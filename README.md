# ğŸ•µï¸â€â™€ï¸ Suspicious Transaction Detector

A simple prototype for demonstrating **fraud detection** using **PySpark**, **PyTest**, and **CI/CD automation**.

This project simulates a lightweight version of a **transaction monitoring pipeline**, focused on detecting potentially suspicious activity based on rapid transactions within a short time window â€” a basic signal often used in **money laundering and fraud prevention** scenarios.

---

## ğŸ¯ Purpose

This is a **1-day prototype** built to demonstrate my ability to:

- ğŸ’¾ Ingest and transform data using **PySpark**
- ğŸ§ª Validate logic using **unit tests with PyTest**
- ğŸ” Integrate tests in a **CI/CD pipeline using GitHub Actions**
- ğŸ” Simulate real-world financial risk logic like transaction spike detection

> This is not a production tool â€” just a compact project to showcase relevant technical and analytical skills for data engineering roles focused on **fraud detection**, **ETL reliability**, and **data pipeline testing**.

---

## ğŸ§± Tech Stack

| Layer       | Tool          |
|-------------|---------------|
| Data Engine | PySpark       |
| Testing     | PyTest        |
| Automation  | GitHub Actions |
| Language    | Python 3.10+  |

---

## ğŸ§ª What It Does

- Loads example transaction data from CSV
- Transforms data (cast types, parse timestamps)
- Applies a basic **fraud rule**:  
  > Flag accounts with more than 3 transactions in 5 minutes
- Uses **PyTest** to ensure:
  - ETL transforms run correctly
  - Schema and types are as expected
  - Fraud rules flag the right rows
- Runs tests automatically on every push via **GitHub Actions**


## ğŸ“‚ Project Structure
fraud-detection-pyspark-pipeline/
â”‚
â”œâ”€â”€ data/                  
â”‚   â””â”€â”€ transactions.csv           # Sample transaction data
â”‚
â”œâ”€â”€ src/                          
â”‚   â”œâ”€â”€ etl.py                     # PySpark data ingestion and transformation
â”‚   â””â”€â”€ fraud_rules.py             # Basic fraud rule logic
â”‚
â”œâ”€â”€ tests/                        
â”‚   â”œâ”€â”€ test_etl.py                # Unit tests for the ETL process
â”‚   â””â”€â”€ test_fraud_rules.py        # Unit tests for fraud detection rules
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ test.yml               # CI pipeline using GitHub Actions
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project overview (this file)


## ğŸ›£ï¸ Future Ideas (if taken further)

- âœ… Add more advanced fraud signals (velocity, country-based anomalies)
- âœ… Integrate Delta Lake or Databricks runtime
- âœ… Load from and write to real cloud data sources (Azure Blob, ADLS)
- âœ… Add anomaly detection using basic ML/AI models
- âœ… Add alerting logic or a Streamlit dashboard for results



## âœ¨ Why I Built This

I'm deeply interested in the intersection of **data engineering and responsible financial systems**. I believe that robust pipelines and smart data validation can prevent real harm â€” not just to institutions, but to people. I built this small project to show how even a simplified system can demonstrate:

- Strategic thinking
- Technical implementation
- Data intuition